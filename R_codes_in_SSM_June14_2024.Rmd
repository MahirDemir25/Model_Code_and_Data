---
title: "R Code for State Space Model of <i>Bosmina longirostris</i> dynamics"
author: "Demir, Mahir"
date: '2024-06-03'
output:
  html_document: default
  pdf_document: default
---

##  We present code in three sections in this document: 
####  1) Implementing the predator-prey model (State Space Model)  
####  2) Model fitting and parameter estimation
####  3) Profile log-likelihood for parameters


## 1) Implementing the predator-prey model

We present R code used in the study titled:"Mechanistic models fit to field time series reveal nonconsumptive and consumptive effects of an invasive predator" 

Below is the code for a state space model (SSM) for <i>Bosmina longirostris</i> dyanamics implemented in the R pomp package. This model includes two effects of the predator, <i>Bythotrephes longimanus</i>: a nonconsumptive effect and a consumptive effect, where the consumptive effect is modified by the temperature gradient. This model was fit to combined site (45m and 110m) data for <i>B. longirostris</i>. 

#### Required R packages
```{}
require(pomp) 
require(lubridate)
require(timeSeries)
```
### Process Model: Equation 1 in Manuscript
```{}
Bosmina_rprocess <- Csnippet("
                            double births;
                            double deaths;
                            double betaz;
                            double dw;

                            if (error_count != 0.0) return;
                            
                            betaz = exp(dot_product(5,&seas_1,&log_betaz1)); // B-spline function for prey birth 

                            dw = rnorm(0,sqrt(dt));       // white noise for prey birth

                            births = betaz*(exp(-eta*byth*(1/(1+ exp(-1*(IP2- JD)))) ))*dt*prey*(1-prey/cc) 
                                    + prey*sdbeta*dw + pulse*rlnorm(meanp,sigmap);	// prey births
                            deaths = prey*(alpha*byth*(1/(1+ exp(-1*(IP- JD))))*(exp( -byth*(FF*Ave_Temp_diff )))
                                    + mu )*dt;	// prey deaths due to predation and natural death (mu)

                            prey += births - deaths;
                            noise += dw;

                            if (prey <= 0.0)  {
                            prey = 0;      
                            }            // check for violations of positivity constraints for prey abundance
                            
                            if (nocoup < 1)  {
                            prey = 0;
                             }            // nonzero error_count variable signals violation
                            ")

```

#### Initial values for paramaters in process model
We specify an initial value for each parameter in the model.
```{}
params.init <- c(taudem= 31.23594,tauenv=0.3414941,taudem2= 31.23594,tauenv2=0.3414941,log.betaz1=-3.946131,log.betaz2=-2.085238,log.betaz3=-1.244633,log.betaz4=-1.254834,log.betaz5=-1.254834,alpha=0.01,FF=0.01,eta=0.1,IP=320, IP2=240, mu= 0.1282482,meanp=6.447619,sigmap= 1.693872,cc=451366.3,sdbeta=0.2263157,prey.0=0,noise.0=0,error_count.0=0)

```

#### Import zooplankton data set
We removed  years and observations that are anomalous observations or outlier data. We removed the year 2000, since abundance of prey density that year was extremely high compared to other years. We also removed observations that were the first positive observation each year when they were followed immediately by a zero. When the first observation of the year is positive, we then expect subsequent observations in early year to also be positive.

In addition, zooplankton data were not available for the years 2004-2006. To sum up, we consider years between 1998,1999,2001-2003,2007-2018 for 45m site (17 years) and 1994-1999, 2001-2003, 2007-2018 for 110m (21 years) Thus, we considered these 38 years in our analysis. 

Since we merge the data for two sites, the first set of years in the time series represents data from the 45 m site and the second set of years represents the 110  site. The years in the code below are given as 1998,1999,2001:2003,2007:2024,2026:2028,2032:2043. The years 1998,1999,2001:2003,2007:2018 represent the 45 m data site and 2019-2024,2026:2028,2032:2043 represent 110 m site.
```{}
zoop<-read.csv("zoop45m_plus_110m.csv",header=TRUE)
zoop<-subset(zoop, Year!=2000) # year 2000 at 45 m data site
zoop<-subset(zoop, Year!=2025) # year 2000 at 110 m data site
zoop<-subset(zoop, day!=4500);zoop<-subset(zoop, day!=4509);zoop<-subset(zoop, day!=4520)  #remove anomalous 3 observations in year 2010 at 45 m data site
zoop<-subset(zoop, day!=14621) #remove anomalous January observation for 110m data set
zoop<-subset(zoop, day!=15113) #remove anomalous observation in year 2014 at 110m data set
```

#### Predator density covariate 
We rescale and smooth the predator (<i>Bythotrephes longimanus</i>) data to reduce the influence of measurement error. Since we do not have data for each day, we use the linear interpolation for any days with missing data.
```{}
# rescale Bythotrephes Biomass (#ind/m2) divding by its standard deviation (sd=372.7):
zoop$Byth_rs<-zoop$Bythotrephes_longimanus/372.7

#generate Bythotrephes covariate
Byth<-rep(c(rep(0,50),rep(NA,315)),46); 
Byth[zoop$day]<-zoop$Byth_rs; Byth[1]<-0;Byth[16790]<-0
Byth<-interpNA(Byth, method = "linear")

#calculate 45 day moving average
Byth_corrected<-Byth+0.00340706. # Set zero observation to min(zoop$Byth_rs)/2=0.00340706 to able to perform the following moving average
BythMA45<-rep(0.00340706,16790) 

for (i in 23:16767) {
  BythMA45[i]<-(Byth_corrected[i-22]*Byth_corrected[i-21]*Byth_corrected[i-20]*Byth_corrected[i-19]*Byth_corrected[i-18]*Byth_corrected[i-17]*
                  Byth_corrected[i-16]*Byth_corrected[i-15]*Byth_corrected[i-14]*Byth_corrected[i-13]*Byth_corrected[i-12]*Byth_corrected[i-11]*
                  Byth_corrected[i-10]*Byth_corrected[i-9]*Byth_corrected[i-8]*
                  Byth_corrected[i-7]*Byth_corrected[i-6]*Byth_corrected[i-5]*Byth_corrected[i-4]*Byth_corrected[i-3]*Byth_corrected[i-2]*
                  Byth_corrected[i-1]*Byth_corrected[i]*Byth_corrected[i+1]*Byth_corrected[i+2]*Byth_corrected[i+3]*Byth_corrected[i+4]*
                  Byth_corrected[i+5]*Byth_corrected[i+6]*Byth_corrected[i+7]*Byth_corrected[i+8]*Byth_corrected[i+9]*
                  Byth_corrected[i+10]*Byth_corrected[i+11]*Byth_corrected[i+12]*Byth_corrected[i+13]*Byth_corrected[i+14]*
                  Byth_corrected[i+15]*Byth_corrected[i+16]*Byth_corrected[i+17]*Byth_corrected[i+18]*Byth_corrected[i+19]*Byth_corrected[i+20]*Byth_corrected[i+21]*Byth_corrected[i+22])^(1/45)
}

#need to back-transform
BythMA45<-BythMA45-0.00340706;BythMA45<-round(BythMA45,10)
```

#### Day of year as a covariate
We generate a vector representing the day of the year for each day over 46 years. Note that the vector includes 1998-2018 for the 45 m site and 1994-2018 for the 110 m site (total 46 years), but in our actual analysis we exclude the years 2000, 2004-2006. Thus we only analyze 46 - 8 = 38 years in our analysis, as noted above (see "Import zooplankton data set" section). 
```{}
jdays<-1:365
JD<-rep(jdays,46)
```
#### Setting population to zero at the end of each season

Since prey species effectively disappear from system at the end of each year (populations overwinter as resting eggs), we set prey abundance to zero at the end of each year.
```{}
nocoup<-rep(c(rep(1,364),0),46)
```

#### Import surface temperature data at Bosmina 45 m site
```{}
#import surface temperature data for #### 45m #####
Tempdata_merge<-read.csv("Surface_Tempdata_for45m.csv",head=T)
Tempdata_merge<-subset(Tempdata_merge,Year!=2000)
Tempdata_merge$day<-as.numeric(1+(as.Date(Tempdata_merge$Date, format="%m/%d/%y")-rep(as.Date("1998-01-01"),length(Tempdata_merge$Date)) ))

#generate surface temperature covariate
Temp<-rep(c(rep(0,100),rep(NA,265)),21);
Temp[Tempdata_merge$day]<-Tempdata_merge$WTMP; Temp[1]<-0;Temp[7665]<-0
Temp<-interpNA(Temp, method = "linear")
Temp<-Temp[1:7665]
```
#### Import temperature gradient data and calculate temperature gradient
We calculate the temperature gradient for the 45 m site.
```{}
## Temp at 40m in Lake Michigan (LM) for 45m
L_Temp<-read.csv("Temp_at40m_Depth_98-18_for45m.csv",header=TRUE)
L_Temp<-subset(L_Temp,Year!=2000)
L_Temp$day<-as.numeric((as.Date( L_Temp$Date, format="%m/%d/%y")-rep(as.Date("1998-01-01"),length(L_Temp$Date)) ))

## covariate of Temp at 40m
l_temp<-rep(c(rep(0,86),rep(NA,279)),21);
l_temp[L_Temp$day]<-L_Temp$Temp_at40m; l_temp[1]<-0;l_temp[7665]<-0
l_temp<-interpNA(l_temp, method = "linear")

Temp_diff45=Temp-l_temp

#replace any negative value with 0
for(i in 1:nrow(Temp_diff45))
{
  if (Temp_diff45[i,1]<0)
    Temp_diff45[i,1]=0
}

```
#### Import surface temperature data for 110 m site
```{}
Tempdata_merge<-read.csv("Tempdata_final_94-18.csv",head=T,sep=";", dec=",")
Tempdata_merge$day<-as.numeric(1+(as.Date(Tempdata_merge$Date)-rep(as.Date("1994-01-01"),length(Tempdata_merge$Date))))

#generate surface temperature covariate
Temp<-rep(c(rep(0,100),rep(NA,265)),25); 
Temp[Tempdata_merge$day]<-Tempdata_merge$WTMP; Temp[1]<-0;Temp[9125]<-0
Temp<-interpNA(Temp, method = "linear")
```
#### Import temperature gradient data for 110 m site
We calculate the temperature gradient for the 110 m site as for the 45 m site.
```{}
L_Temp<-read.csv("Temp_at40m_94-18_full.csv",header=TRUE,sep=",")
L_Temp$day<-as.numeric((as.Date( L_Temp$Date, format="%m/%d/%y")-rep(as.Date("1994-01-01"),length(L_Temp$Date)) ))

## covariate of Temp at 40m
l_temp<-rep(c(rep(0,86),rep(NA,279)),25);
l_temp[L_Temp$day]<-L_Temp$Temp_at40m; l_temp[1]<-0;l_temp[9125]<-0
l_temp<-interpNA(l_temp, method = "linear")

## Temp difference (Temperature gradient)
Temp_diff110m=Temp-l_temp

#replace any negative value with 0
for(i in 1:nrow(Temp_diff110m))
{
  if (Temp_diff110m[i,1]<0)
    Temp_diff110m[i,1]=0
}
```
#### Merging temperature gradients for 45 m and 110m sites
```{}
Temp_diff<-c(Temp_diff45,Temp_diff110m)
```
#### Obtaining average temperature gradient for <i>Bosmina</i> combined site data set (45m and 110m)
We obtain the average temperature gradient for each day of the year, calculated across years.
```{}
Tempp=Temp_diff
# obtain the avaraged julian year for Temp data at 45 m site
Temp1998<-Tempp[1:365]
Temp1999<-Tempp[366:730]
Temp2000<-Tempp[731:1095]
Temp2001<-Tempp[1096:1460]
Temp2002<-Tempp[1461:1825]
Temp2003<-Tempp[1826:2190]

Temp2004<-Tempp[2191:2555]
Temp2005<-Tempp[2556:2920]
Temp2006<-Tempp[2921:3285]

Temp2007<-Tempp[3286:3650]
Temp2008<-Tempp[3651:4015]
Temp2009<-Tempp[4016:4380]
Temp2010<-Tempp[4381:4745]
Temp2011<-Tempp[4746:5110]
Temp2012<-Tempp[5111:5475]
Temp2013<-Tempp[5476:5840]
Temp2014<-Tempp[5841:6205]
Temp2015<-Tempp[6206:6570]
Temp2016<-Tempp[6571:6935]
Temp2017<-Tempp[6936:7300]
Temp2018<-Tempp[7301:7665]


# obtain the avaraged for Byth data vs julian year for 110 m site
Temp2019<-Tempp[7666:8030]     # corresponds year 1994 in 110m site
Temp2020<-Tempp[8031:8395]     # corresponds year 1995 in 110m site
Temp2021<-Tempp[8396:8760]     # corresponds year 1996 in 110m site
Temp2022<-Tempp[8761:9125]     # corresponds year 1997 in 110m site
Temp2023<-Tempp[9126:9490]     # corresponds year 1998 in 110m site
Temp2024<-Tempp[9491:9855]     # corresponds year 1999 in 110m site
Temp2025<-Tempp[9856:10220]    # corresponds year 2000 in 110m site 
Temp2026<-Tempp[10221:10585]   # corresponds year 2001 in 110m site
Temp2027<-Tempp[10586:10950]   # corresponds year 2002 in 110m site
Temp2028<-Tempp[10951:11315]   # corresponds year 2003 in 110m site

Temp2029<-Tempp[11316:11680]   # corresponds year 2004 in 110m site
Temp2030<-Tempp[11681:12045]   # corresponds year 2005 in 110m site
Temp2031<-Tempp[12046:12410]   # corresponds year 2006 in 110m site

Temp2032<-Tempp[12411:12775]   # corresponds year 2007 in 110m site
Temp2033<-Tempp[12776:13140]   # corresponds year 2008 in 110m site
Temp2034<-Tempp[13141:13505]   # corresponds year 2009 in 110m site
Temp2035<-Tempp[13506:13870]   # corresponds year 2010 in 110m site
Temp2036<-Tempp[13871:14235]   # corresponds year 2011 in 110m site
Temp2037<-Tempp[14236:14600]   # corresponds year 2012 in 110m site
Temp2038<-Tempp[14601:14965]   # corresponds year 2013 in 110m site
Temp2039<-Tempp[14966:15330]   # corresponds year 2014 in 110m site
Temp2040<-Tempp[15331:15695]   # corresponds year 2015 in 110m site
Temp2041<-Tempp[15696:16060]   # corresponds year 2016 in 110m site
Temp2042<-Tempp[16061:16425]   # corresponds year 2017 in 110m site
Temp2043<-Tempp[16426:16790]   # corresponds year 2018 in 110m site


# mean of temperature gradient for 38 years with excluding the years 2000, 2004-2006 from both sites(45m and 110m)
Temp_diff_m<- rowMeans(cbind(Temp1998,Temp1999,Temp2001,Temp2002,Temp2003,Temp2007,Temp2008,Temp2009,Temp2010,Temp2011,Temp2012,Temp2013,Temp2014,Temp2015,Temp2016,Temp2017,Temp2018,
                          Temp2019,Temp2020,Temp2021,Temp2022,Temp2023,Temp2024,Temp2026,Temp2027,Temp2028,Temp2032,Temp2033,Temp2034,Temp2035,Temp2036,Temp2036,Temp2038,Temp2039,Temp2040,Temp2041,Temp2042,Temp2043))
Ave_Temp_diff<-rep(Temp_diff_m,46) # we obtained average temperature gradient and used for 46 years (Actually 38 years since years 2000, 2004-2006 are excluded from both sites in this calculation) 

```
#### Initiation of dynamics each year
Dynamics each year are initiated by a "pulse". To identify the date of pulse, we find the first positive observation each year.
```{}
zoop$year<-zoop$Year
surveyyears<-c(1998,1999,2001:2003,2007:2024,2026:2028,2032:2043)
firstdaph<-rep(0,38)
firstdaphjday<-rep(0,38)
firstdaphdens<-rep(0,38)

for (i in 1:38) {
  zoopyear<-subset(zoop,year==surveyyears[i])
  zoopyearno0<-subset(zoopyear,Bosmina_longirostris>0)
  firstdaph[i]<-zoopyearno0$day[which.min(zoopyearno0$DOY)]
  firstdaphjday[i]<-zoopyearno0$DOY[which.min(zoopyearno0$DOY)]
  firstdaphdens[i]<-zoopyearno0$Bosmina_longirostris[which.min(zoopyearno0$DOY)]
}

```
Each year, the pulse starts 7 days before the first positive observation.
```{}
daphstart<-firstdaph-7 
```
We create a vector with 1s at the times of the first observation each year.
```{}
pulse<-rep(0,16790)
pulse[daphstart]<-1
```
We generate a subset of observations excluding early-year zero observations (i.e., zeroes observed before the first positive observation for each year).
```{}
rem.days<-0
for (i in 1:38) {
  zoopyear<-subset(zoop,year==surveyyears[i])
  zoopyear0<-subset(zoopyear,day<firstdaph[i])
  rem.days<-c(rem.days,zoopyear0$day)
}
rem.days<-rem.days[2:65]
zoopsubset<-zoop
for (i in 1:64) {
  zoopsubset<-subset(zoopsubset,day!=rem.days[i])
}
```
##### Allowing different measurement error paramaters for each site
The model includes separate measurement error parameters for each site. Between the time interval 1 to 7665 (corresponding to 45 m data), we estimate measurement error for the 45 m site; after day 7665 (corresponding to 110 m data set), we estimate measurement error for the 110 m site. 
```{}
S_45<-c(rep(1,7665), rep(0,9125))
S_110<-c(rep(0,7665), rep(1,9125))
```
##### Covariate table
We construct a table containing all covariates.
```{}
covartable <- covariate_table(
  t=seq(from=0,to=16789,by=1),
  seas=periodic_bspline_basis(t,nbasis=5,degree=3,period=365),
  byth=BythMA45,
  nocoup= nocoup,
  S_45=S_45,
  S_110=S_110,
  Ave_Temp_diff=Ave_Temp_diff,
  JD= JD,
  pulse=pulse,
  times="t"
)
```
##### Specification of the measurement model
We specify the measurement model (Eqs. 9 and 10 in manuscript).
```{}

Bosmina_rmeasure <- Csnippet("
                                 
                                  double tau, bosmina;
                                  tau=sqrt(taudem*taudem*prey*S_45 + tauenv*tauenv*prey*prey*S_45 
                                      +taudem2*taudem2*prey*S_110 + tauenv2*tauenv2*prey*prey*S_110);
                                  if ((error_count > 0.0) || (!(R_FINITE(prey)))) {
                                  Bosmina_longirostris = R_NaReal;
                                  } else {
                                  bosmina = rnorm(prey,tau);
                                  if (bosmina<=0) {
                                  Bosmina_longirostris=0;
                                  }
                                  else {
                                  Bosmina_longirostris=bosmina;
                                  }
                                  }
                                  ")
```

```{}
Bosmina_dmeasure <- Csnippet("
                                   double tau, tol = 1.0e-18;
                                  tau=sqrt(taudem*taudem*prey*S_45 + tauenv*tauenv*prey*prey*S_45 
                                      +taudem2*taudem2*prey*S_110 + tauenv2*tauenv2*prey*prey*S_110);
                                  double f = 0.0;
                                  if ((error_count > 0.0) || (!(R_FINITE(prey)))) {
                                  lik = tol;
                                  } else {
                                  if (Bosmina_longirostris==0) {
                                  f += pnorm(0,prey,tau,1,1)+tol;
                                  }
                                  else {
                                  f += dnorm(Bosmina_longirostris, prey, tau, 1)+tol;
                                  }
                                  lik = (give_log) ? f : exp(f);
                                  }
                                  ")

```
##### Parameter transformations for estimation
A log transformation is implemented for estimation of those parameters constrained to be positive.
```{}

Bosmina_untrans <- Csnippet("
                       T_taudem = log(taudem);
                       T_tauenv = log(tauenv);
                       T_taudem2 = log(taudem2);
                       T_tauenv2 = log(tauenv2);
                       T_cc = log(cc);
                       T_sdbeta = log(sdbeta);
                       T_mu = log(mu);
                       T_sigmap = log(sigmap);
                       T_eta = log(eta);
                       T_alpha = log(alpha);
                       T_IP = log(IP);
                       T_IP2 = log(IP2);
                      
                       ")
```
Those parameters are then back-transformed to the natural scale after estimation.
```{}

Bosmina_trans <- Csnippet("
                     taudem = exp(T_taudem);
                     tauenv = exp(T_tauenv);
                     taudem2 = exp(T_taudem2);
                     tauenv2 = exp(T_tauenv2);
                     cc = exp(T_cc);
                     sdbeta = exp(T_sdbeta);
                     mu = exp(T_mu);
                     sigmap = exp(T_sigmap);
                     eta = exp(T_eta);
                     alpha = exp(T_alpha);
                     IP = exp(T_IP);
                     IP2 = exp(T_IP2);
                
                     ")

```
### Pomp object
We build the pomp object, which includes the different components generated above.
```{}
Bosmina_pomp <- pomp(
  data=subset(zoopsubset,select=c("Bosmina_longirostris","day")),
  times="day",
  t0=0,
  params=params.init,
  rprocess = euler(step.fun = Bosmina_rprocess, delta.t=1), 
  rmeasure= Bosmina_rmeasure,
  dmeasure = Bosmina_dmeasure,
  covar=covartable,  
  obsnames = c("Bosmina_longirostris"),
  accumvars = c("error_count"), # zeronames ---> accumvars
  statenames = c("prey","noise","error_count"),
  paramnames = c("taudem","tauenv","taudem2","tauenv2","log.betaz1","alpha","FF","IP2","IP","cc","mu","eta","sdbeta","meanp","sigmap","prey.0","noise.0","error_count.0"),
  covarnames = c("seas_1","byth","nocoup","pulse","JD","Ave_Temp_diff","S_45","S_110"),
  partrans=parameter_trans( toEst=Bosmina_untrans, fromEst=Bosmina_trans)
)

```

We generate a simulation and plot.
```{}
Bosmina_sim<-simulate(Bosmina_pomp)
plot(Bosmina_sim)
plot(Bosmina_sim, variables=c("Bosmina_longirostris"))
```


## 2) Model fitting and parameter estimation
To perform the model fitting, we perform 100 searches of parameter space using the mif2 function. The searches are initiated from a randomly drawn set of initial parameter values.  We then evaluate which of the 100 searches provides the maximum log-likelihood estimate and obtain parameter estimates.
```{r}
JOBS<-100 ##update for flux 100
```
We use parallel computing to perform multiple searches simultaneously. In this case, we used 34 cores to complete the 100 searches.
```{}
require(doParallel)
registerDoParallel(cores=as.numeric(Sys.getenv("SLURM_CPUS_ON_NODE")[1]))
```
To calculate run time of the code, we track the initial time that the entire run is initiated.
```{}
tic <- Sys.time()
```
#### We use the following chunk of code for parameter estimation
We run 100 jobs here and input the model code from a separate file, "Bosmina_in_SSM.R" (which includes the code in the "Implementing the predator-prey model" section above), here
```{}
mpar <- foreach(
  i=1:JOBS,
  .packages=c('pomp'),
  .inorder=FALSE) %dopar% {
    Sys.sleep(i*.1)

    NMIF<-200 ## Number of iterations 200
    NP<-40000 ## Number of particles 40000
    METHOD="mif2" ## Iterated filtering is implemented in the mif2 function
    source("Bosmina_in_SSM.R")
    param.tab <- read.table("params.csv", sep=",",row.names=1, header=TRUE)
    LV.pars <- c("taudem","tauenv","taudem2","tauenv2","log.betaz1","log.betaz2","log.betaz3","log.betaz4","log.betaz5","IP","alpha","FF","IP2","mu","cc","eta","sdbeta","meanp","sigmap")
    LV.ivps <- c("prey.0")
    LV.rw.sd<- rw.sd(taudem=0.02, tauenv=0.02,taudem2=0.02,tauenv2=0.02,log.betaz1=0.02,log.betaz2=0.02,log.betaz3=0.02,log.betaz4=0.02,log.betaz5=0.02, alpha=0.005, IP=0.02,IP2=0.02,FF=0.005,mu=0.02, cc=0.02,eta=0.02,sdbeta=0.02,meanp=0.02,sigmap=0.02) # Random walk intensity of params

    LV.hyperparams <-
      list(min=unlist(param.tab["lower.bound",]),max=unlist(param.tab["upper.bound",]))
    
    LV.rprior <- function(hyperparams, ...)
    {
      r<-runif(length(hyperparams$min),min=hyperparams$min,max=hyperparams$max)
      names(r) <- names(hyperparams$min)
      return(r)
    }
    set.seed(8100+i)
    Sys.sleep(i*0.1)
    th.draw <-LV.rprior(LV.hyperparams)
    m<-try(mif2(Bosmina_pomp,
               Nmif=NMIF,
               params=th.draw,
               rw.sd=LV.rw.sd,
               Np=NP,
               cooling.type='geometric',
               cooling.fraction= 0.3,
    ))
    list(pomp=m,params=th.draw)
  }
```
##### We use the outputs from above as input to a particle filter, which we use to calculate the log-liklihood estimate.
```{}
m.out <- rbind(
      pf.lik = sapply(mpar,function(x){
        if(class(x$pomp)=="mif2d_pomp") logLik(x$pomp) else NA
      }),
      sapply(mpar,function(x) {
        if(class(x$pomp)=="mif2d_pomp") coef(x$pomp) else rep(NA,length(coef(Bosmina_pomp)))
      }),
      sapply(mpar,function(x)x$params)
    )
```
##### We save the output (m.out) as rda file.
```{}
save(m.out,mpar,file="out.rda")
```
We print the time to see how long the preceding steps took to run.
```{}
toc <- Sys.time()
print(toc-tic)
```

## 3) Profile log-likelihood for parameters

#### We perform profile likelihood analysis to estimate the 95% confidence intervals for individiaul parameters. As we did for the model fitting, we use parallel computing and request multiple cores in HPCC system to perform multiple searches through parameter space simultaneously.
```{}
require(doParallel)
registerDoParallel(cores=as.numeric(Sys.getenv("SLURM_CPUS_ON_NODE")[1]))
```
We call the Bosmina SSM code.
```{}
source("Bosmina_in_SSM.R")
```
Here, we will generate the profile likelihood for alpha (attack rate). We specify a range of different values for each of the other parameters, which will be used to initiate the model fitting steps involved in generating the likelihood profile.
```{}
estpars <- setdiff(names(params.init),c("alpha","prey.0","noise.0","error_count.0"))
theta.t <- partrans(Bosmina_pomp,params.init,"toEst")
theta.t.hi <- theta.t.lo <- theta.t 
theta.t.lo[estpars] <- theta.t[estpars]-log(2) 
theta.t.hi[estpars] <- theta.t[estpars]+log(2)
```
We specify a range of possible values for the parameter alpha over which we will example the likelihood profile (i.e., how the maximum likelihood estimate of the model changes as we fix alpha at different values and estimate all other parameters).
```{}
profile_design( alpha=seq(from=-3.5,to=-1,length=25), # range of param we get profile likelihood
               lower=theta.t.lo, upper=theta.t.hi,nprof=100  # nprof is number of jobs 100
) -> pd
pd <- as.data.frame(t(partrans(Bosmina_pomp,t(pd),"fromEst"))) 

```
We set the magnitude of the step size (standard deviation) for the random walk for alpha = 0.0 and the rest of parameters 0.02 in "rw.sd" ( Since FF and mu are very small, we set their random walk as 0.005). This will allow us to  estimate the rest of the parameters conditioned on fixed alpha values. In this case, we created 25 different fixed values for alpha above using the profile_desing function and estimate the other parameters for each value of alpha and the corresponding log-likelihood. We can then examine how the log-likelihood of the model changes as the value of alpha changes, which we use to generate 95% confidence intervals.

We obtain outputs as a rdm file as "alpha-profile.rds".
```{}
bake("alpha-profile.rds",{

  foreach (p=iter(pd,"row"), 
           .combine=rbind,
           .errorhandling="remove",
           .inorder=FALSE, .options.mpi=list(chunkSize=1,seed=1598260027L,info=TRUE)
  ) %dopar% {

    require(magrittr) 
    require(plyr) 
    require(reshape2) 
    require(pomp)
    
    options(stringsAsFactors=FALSE) 
    dat<-subset(zoopsubset,select=c("Bosmina_longirostris","day"))
  #   p=pd[1,]
    dat %>% pomp(
      times="day",
      t0=0,
      params=params.init,
      rprocess = euler(step.fun = Bosmina_rprocess, delta.t=1), 
      rmeasure= Bosmina_rmeasure,
      dmeasure = Bosmina_dmeasure,
      covar=covartable,
      obsnames = c("Bosmina_longirostris"),
      accumvars = c("error_count"),
      statenames = c("prey","noise","error_count"),
      paramnames = c("taudem","tauenv","taudem2","tauenv2","log.betaz1","alpha","FF","IP2","IP","cc","mu","eta","sdbeta","meanp","sigmap","prey.0","noise.0","error_count.0"),
      covarnames = c("seas_1","byth","nocoup","pulse","JD","Ave_Temp_diff","S_45","S_110"),
      partrans=parameter_trans( toEst=Bosmina_untrans, fromEst=Bosmina_trans)
    ) %>%
      mif2(params = unlist(p),
           Nmif = 75, # 75
           rw.sd = rw.sd(taudem=0.02, tauenv=0.02,taudem2=0.02,tauenv2=0.02,log.betaz1=0.02,log.betaz2=0.02,log.betaz3=0.02,log.betaz4=0.02,log.betaz5=0.02, alpha=0.0, IP=0.02,IP2=0.02,FF=0.005,mu=0.005, cc=0.02,eta=0.02,sdbeta=0.02,meanp=0.02,sigmap=0.02),
           Np = 4000, # 4000
           cooling.type = "geometric", 
           cooling.fraction.50 = 0.1, 
           ) %>%
      mif2() -> mf
    ## Runs 10 particle filters to assess Monte Carlo error in likelihood 
    pf <- replicate(10, pfilter(mf, Np = 4000))  # rep 10 and Np=4000
    ll <- sapply(pf,logLik)
    ll <- logmeanexp(ll, se = TRUE)

    data.frame(as.list(coef(mf)), 
               logLik = ll[1],
               logLik.se = ll[2]
)
  }
}) -> alpha_profile
```
